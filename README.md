# MLSecOps Field Manual™

A project of **MLSecOps Labs™**.

The **MLSecOps Field Manual™** is a reproducible library of small MLSecOps modules and patterns.

The project grows slowly out of a private MLSecOps Lab and focuses on:

- **Reality** – every module is based on something that actually ran in the lab.   
- **Reproducibility** – small, self-contained scenarios over giant monolithic labs.   
- **Operational clarity** – logs, metrics, and failure modes.

---

## Module roadmap

Initial modules follow the roadmap in the Concept document, starting with:

1. **Module 1 — Evasion Attack: Logs + Mitigation**
    
2. Safe model loading
    
3. LLM jailbreak + logging + mitigation
    
4. Retrieval poisoning (RAG)
    
5. Embedding drift detection
    
6. Agent tool misconfiguration demo  
    … and more over time.

---

## Status

- ✅ Module 1 Complete

---

**AI-Assisted Engineering Disclosure**

This project was developed using a **hybrid workflow** that combines:

* Human-driven engineering
* AI-assisted drafting, coding, review, and research
* Manual validation, correction, and iteration by the author

AI tools were used as **assistants**, not autonomous agents.
All infrastructure, configurations, testing, integrations, and final decisions were performed by the author in a **hands-on, human-led manner**.

The goals for AI-assisted development were:
* Accelerating experimentation
* Exploring multiple design/attack/defense patterns
* Reducing boilerplate work
* Improving clarity and documentation
* Learning through guided iteration

Every module, configuration, and implementation was manually validated and reproduced to ensure understanding, accuracy, and transparency.

---

## License

This project is licensed under the **MIT License** – see `LICENSE` for details.

---

*MLSecOps Labs™ and MLSecOps Field Manual™ are unregistered trademarks of Richard Spicer.*
